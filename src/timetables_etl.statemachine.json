{
  "StartAt": "Process Input",
  "QueryLanguage": "JSONata",
  "States": {
    "Process Input": {
      "Type": "Pass",
      "Next": "Validate Lock Inputs",
      "Assign": {
        "inputDataSource": "{% $states.input.inputDataSource %}",
        "datasetRevisionId": "{% $states.input.datasetRevisionId %}",
        "datasetType": "{% $states.input.datasetType %}",
        "url": "{% $exists($states.input.url) ? $states.input.url : null %}",
        "s3Bucket": "{% $exists($states.input.s3.bucket) ? $states.input.s3.bucket : '${DefaultS3BucketName}' %}",
        "s3Object": "{% $exists($states.input.s3.object) ? $states.input.s3.object : null %}",
        "publishDatasetRevision": "{% $exists($states.input.publishDatasetRevision) ? $states.input.publishDatasetRevision : false %}",
        "overwriteInputDataset": "{% $exists($states.input.overwriteInputDataset) ? $states.input.overwriteInputDataset : true %}",
        "datasetETLTaskResultId": "{% $exists($states.input.datasetETLTaskResultId) ? $states.input.datasetETLTaskResultId : null %}",
        "lock_name": "bods-backend-semaphore",
        "concurrency_limit": 10,
        "lock_entry": "{% $uuid() %}"
      }
    },
    "Validate Lock Inputs": {
      "Type": "Choice",
      "Default": "Lock Configuration Error",
      "Choices": [
        {
          "Condition": "{% $exists($lock_name) and $type($lock_name) = 'string' and $exists($concurrency_limit) and $type($concurrency_limit) = 'number' and $exists($lock_entry) and $type($lock_entry) = 'string' %}",
          "Next": "Acquire Lock"
        }
      ]
    },
    "Lock Configuration Error": {
      "Type": "Fail",
      "Error": "InsufficientLockInput",
      "Cause": "Lock parameters are missing or invalid"
    },
    "Acquire Lock": {
      "Comment": "Acquire a lock using a conditional update to DynamoDB",
      "Type": "Task",
      "Resource": "arn:aws:states:::dynamodb:updateItem",
      "Assign": {
        "lockacquiredtime": "{% $states.context.State.EnteredTime %}"
      },
      "Arguments": {
        "TableName": "${TimetablesSemaphoreDynamoDbTableName}",
        "Key": {
          "LockName": {
            "S": "{% $lock_name %}"
          }
        },
        "ExpressionAttributeNames": {
          "#currentlockcount": "currentlockcount",
          "#lockownerid": "{% $lock_entry %}"
        },
        "ExpressionAttributeValues": {
          ":increase": {
            "N": "1"
          },
          ":limit": {
            "N": "{% $string($concurrency_limit) %}"
          },
          ":lockacquiredtime": {
            "S": "{% $states.context.State.EnteredTime %}"
          }
        },
        "UpdateExpression": "SET #currentlockcount = #currentlockcount + :increase, #lockownerid = :lockacquiredtime",
        "ConditionExpression": "currentlockcount <> :limit and attribute_not_exists(#lockownerid)",
        "ReturnValues": "UPDATED_NEW"
      },
      "Retry": [
        {
          "ErrorEquals": [
            "DynamoDB.AmazonDynamoDBException"
          ],
          "MaxAttempts": 0
        },
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "MaxAttempts": 6,
          "BackoffRate": 2
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "DynamoDB.AmazonDynamoDBException"
          ],
          "Next": "Initialize Lock Item",
          "Output": "$lockinfo.acquisitionerror"
        },
        {
          "ErrorEquals": [
            "DynamoDB.ConditionalCheckFailedException"
          ],
          "Next": "Get Current Lock Record",
          "Output": "$lockinfo.acquisitionerror"
        },
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "$.error",
            "stepName": "Acquire Lock"
          }
        }
      ],
      "Next": "Initialize Pipeline"
    },
    "Initialize Lock Item": {
      "Comment": "Create the initial lock record if it doesn't exist",
      "Type": "Task",
      "Resource": "arn:aws:states:::dynamodb:putItem",
      "Arguments": {
        "TableName": "${TimetablesSemaphoreDynamoDbTableName}",
        "Item": {
          "LockName": {
            "S": "{% $lock_name %}"
          },
          "currentlockcount": {
            "N": "0"
          }
        },
        "ConditionExpression": "LockName <> :lockname",
        "ExpressionAttributeValues": {
          ":lockname": {
            "S": "{% $lock_name %}"
          }
        }
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Acquire Lock"
        }
      ],
      "Next": "Acquire Lock"
    },
    "Get Current Lock Record": {
      "Comment": "Check if this execution already holds a lock",
      "Type": "Task",
      "Resource": "arn:aws:states:::dynamodb:getItem",
      "Arguments": {
        "TableName": "${TimetablesSemaphoreDynamoDbTableName}",
        "ExpressionAttributeNames": {
          "#lockownerid": "{% $lock_entry %}"
        },
        "Key": {
          "LockName": {
            "S": "{% $lock_name %}"
          }
        },
        "ProjectionExpression": "#lockownerid"
      },
      "Assign": {
        "Item": "{% $states.result.Item %}",
        "ItemString": "{% $string($states.result.Item) %}"
      },
      "Output": "$lockinfo.currentlockitem",
      "Next": "Check If Lock Already Acquired"
    },
    "Check If Lock Already Acquired": {
      "Comment": "Verify if this execution already has a lock",
      "Type": "Choice",
      "Choices": [
        {
          "Condition": "{% $exists($ItemString) and $contains($ItemString, 'Z') %}",
          "Next": "Initialize Pipeline"
        }
      ],
      "Default": "Wait to Get Lock"
    },
    "Wait to Get Lock": {
      "Comment": "Wait before retrying to acquire the lock",
      "Type": "Wait",
      "Seconds": 30,
      "Next": "Acquire Lock"
    },
    "Initialize Pipeline": {
      "Type": "Task",
      "Next": "Route By Input Type",
      "Resource": "${InitializePipelineLambdaArn}",
      "Arguments": {
        "Bucket": "{% $s3Bucket %}",
        "ObjectKey": "{% $s3Object %}",
        "DatasetRevisionId": "{% $datasetRevisionId %}",
        "DatasetETLTaskResultId": "{% $datasetETLTaskResultId %}"
      },
      "Assign": {
        "DatasetEtlTaskResultId": "{% $states.result.DatasetEtlTaskResultId %}"
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "{% $states.errorOutput %}",
            "stepName": "Initialize Pipeline"
          }
        }
      ]
    },
    "Route By Input Type": {
      "Type": "Choice",
      "Default": "Overall State Machine Failed",
      "Choices": [
        {
          "Condition": "{% $inputDataSource = 'URL_DOWNLOAD' and $url != null %}",
          "Next": "Download Dataset"
        },
        {
          "Condition": "{% $inputDataSource = 'S3_FILE' and $s3Bucket != null and $s3Object != null %}",
          "Next": "ClamAV and Extraction"
        }
      ]
    },
    "Download Dataset": {
      "Type": "Task",
      "Next": "ClamAV and Extraction",
      "Resource": "${DownloadDatasetLambdaArn}",
      "Arguments": {
        "Url": "{% $url %}",
        "Bucket": "{% $s3Bucket %}",
        "DatasetType": "{% $datasetType %}",
        "DatasetRevisionId": "{% $datasetRevisionId %}",
        "DatasetEtlTaskResultId": "{% $DatasetEtlTaskResultId %}"
      },
      "Assign": {
        "s3Bucket": "{% $states.result.s3.bucket %}",
        "s3Object": "{% $states.result.s3.object %}"
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "{% $states.errorOutput %}",
            "stepName": "Download Dataset"
          }
        }
      ]
    },
    "ClamAV and Extraction": {
      "Type": "Task",
      "Next": "Validation and File Attributes",
      "Resource": "${ClamAvScannerLambdaArn}",
      "Arguments": {
        "Bucket": "{% $s3Bucket %}",
        "ObjectKey": "{% $s3Object %}",
        "DatasetRevisionId": "{% $datasetRevisionId %}",
        "DatasetType": "{% $datasetType %}",
        "DatasetEtlTaskResultId": "{% $DatasetEtlTaskResultId %}"
      },
      "Assign": {
        "ExtractedSubFolder": "{% $states.result.body.generatedPrefix %}"
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "{% $states.errorOutput %}",
            "stepName": "ClamAV and Extraction"
          }
        }
      ]
    },
    "Validation and File Attributes": {
      "Type": "Map",
      "Next": "Collate Files",
      "MaxConcurrency": 100,
      "ToleratedFailurePercentage": 100,
      "ItemSelector": {
        "mapS3Bucket": "{% $s3Bucket %}",
        "mapS3Object": "{% $states.context.Map.Item.Value.Key %}",
        "mapDatasetRevisionId": "{% $datasetRevisionId %}",
        "mapDatasetEtlTaskResultId": "{% $DatasetEtlTaskResultId %}",
        "mapDatasetType": "{% $datasetType %}"
      },
      "ItemReader": {
        "Resource": "arn:aws:states:::s3:listObjectsV2",
        "Arguments": {
          "Bucket": "{% $s3Bucket %}",
          "Prefix": "{% $ExtractedSubFolder %}"
        }
      },
      "ItemProcessor": {
        "ProcessorConfig": {
          "Mode": "DISTRIBUTED",
          "ExecutionType": "STANDARD"
        },
        "StartAt": "Process Validation Map Input",
        "States": {
          "Process Validation Map Input": {
            "Type": "Pass",
            "Next": "File Validation",
            "Assign": {
              "Bucket": "{% $states.input.mapS3Bucket %}",
              "ObjectKey": "{% $states.input.mapS3Object %}",
              "DatasetRevisionId": "{% $states.input.mapDatasetRevisionId %}",
              "datasetEtlTaskResultId": "{% $states.input.mapDatasetEtlTaskResultId %}",
              "DatasetType": "{% $states.input.mapDatasetType %}"
            }
          },
          "File Validation": {
            "Type": "Task",
            "Next": "XSD Schema Check",
            "Resource": "${FileValidationLambdaArn}",
            "Arguments": {
              "Bucket": "{% $Bucket %}",
              "ObjectKey": "{% $ObjectKey %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}"
            },
            "Output": {
              "fileValidation": "{% $states.result %}"
            },
            "Catch": [
              {
                "ErrorEquals": [
                  "States.ALL"
                ],
                "Next": "Validation Exception Handler",
                "Output": {
                  "errorInfo": "{% $states.errorOutput %}",
                  "stepName": "File Validation"
                }
              }
            ]
          },
          "XSD Schema Check": {
            "Type": "Task",
            "Next": "Post Schema Check",
            "Resource": "${SchemaCheckLambdaArn}",
            "Arguments": {
              "Bucket": "{% $Bucket %}",
              "ObjectKey": "{% $ObjectKey %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}"
            },
            "Output": {
              "schemaCheck": "{% $states.result %}"
            },
            "Catch": [
              {
                "ErrorEquals": [
                  "States.ALL"
                ],
                "Next": "Validation Exception Handler",
                "Output": {
                  "errorInfo": "{% $states.errorOutput %}",
                  "stepName": "XSD Schema Check"
                }
              }
            ]
          },
          "Post Schema Check": {
            "Type": "Task",
            "Next": "FileAttributes ETL",
            "Resource": "${PostSchemaCheckLambdaArn}",
            "Arguments": {
              "Bucket": "{% $Bucket %}",
              "ObjectKey": "{% $ObjectKey %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}"
            },
            "Output": {
              "postSchemaCheck": "{% $states.result %}"
            },
            "Catch": [
              {
                "ErrorEquals": [
                  "States.ALL"
                ],
                "Next": "Validation Exception Handler",
                "Output": {
                  "errorInfo": "{% $states.errorOutput %}",
                  "stepName": "Post Schema Check"
                }
              }
            ]
          },
          "FileAttributes ETL": {
            "Type": "Task",
            "Next": "Validation Success",
            "Resource": "${FileAttributesEtlLambdaArn}",
            "Arguments": {
              "Bucket": "{% $Bucket %}",
              "ObjectKey": "{% $ObjectKey %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}"
            },
            "Assign": {
              "fileAttributesEtl": "{% $states.result.id %}"
            },
            "Catch": [
              {
                "ErrorEquals": [
                  "States.ALL"
                ],
                "Next": "Validation Exception Handler",
                "Output": {
                  "errorInfo": "{% $states.errorOutput %}",
                  "stepName": "FileAttributes ETL"
                }
              }
            ]
          },
          "Validation Success": {
            "Type": "Succeed"
          },
          "Validation Exception Handler": {
            "Type": "Task",
            "Next": "Validation Failed",
            "Resource": "${ExceptionHandlerLambdaArn}",
            "Arguments": {
              "Error": "{% $states.input.errorInfo.Error %}",
              "Cause": "{% $states.input.errorInfo.Cause %}",
              "DatasetEtlTaskResultId": "{% $states.input.mapDatasetEtlTaskResultId %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}",
              "DatasetType": "{% $DatasetType %}",
              "StepName": "{% $states.input.stepName %}",
              "ObjectKey": "{% $ObjectKey %}",
              "FailDatasetRevision": false,
              "FailDatasetETLTaskResult": false
            }
          },
          "Validation Failed": {
            "Type": "Fail",
            "Comment": "Processing Single File in ETL Failed"
          }
        }
      },
      "Output": {
        "validationMapResults": "{% $states.result %}"
      },
      "ResultWriter": {
        "Resource": "arn:aws:states:::s3:putObject",
        "Arguments": {
          "Bucket": "{% $s3Bucket %}",
          "Prefix": "tt-file-attributes-map-results"
        }
      }
    },
    "Collate Files": {
      "Type": "Task",
      "Next": "PTI and ETL",
      "Resource": "${CollateFilesLambdaArn}",
      "Arguments": {
        "MapRunArn": "{% $states.input.validationMapResults.MapRunArn %}",
        "MapRunPrefix": "tt-file-attributes-map-results",
        "Bucket": "{% $s3Bucket %}",
        "DatasetRevisionId": "{% $datasetRevisionId %}"
      },
      "Assign": {
        "EtlFileListJson": "{% $states.result.EtlFileListJsonS3ObjectKey %}"
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "{% $states.errorOutput %}",
            "stepName": "Collate Files"
          }
        }
      ]
    },
    "PTI and ETL": {
      "Type": "Map",
      "Next": "Generate Output Zip and Update Status",
      "MaxConcurrency": 100,
      "ToleratedFailurePercentage": 100,
      "ItemSelector": {
        "mapS3Bucket": "{% $states.context.Map.Item.Value.Bucket %}",
        "mapS3Object": "{% $states.context.Map.Item.Value.ObjectKey %}",
        "mapDatasetSupersededTimetable": "{% $states.context.Map.Item.Value.SupersededTimetable %}",
        "mapDatasetEtlTaskResultId": "{% $DatasetEtlTaskResultId %}",
        "mapDatasetFileAttributesEtl": "{% $states.context.Map.Item.Value.TxcFileAttributesId %}",
        "mapDatasetRevisionId": "{% $datasetRevisionId %}",
        "mapDatasetType": "{% $datasetType %}"
      },
      "ItemReader": {
        "Resource": "arn:aws:states:::s3:getObject",
        "ReaderConfig": {
          "InputType": "JSON"
        },
        "Arguments": {
          "Bucket": "{% $s3Bucket %}",
          "Key": "{% $EtlFileListJson %}"
        }
      },
      "ItemProcessor": {
        "ProcessorConfig": {
          "Mode": "DISTRIBUTED",
          "ExecutionType": "STANDARD"
        },
        "StartAt": "Process ETL Map Input",
        "States": {
          "Process ETL Map Input": {
            "Type": "Pass",
            "Next": "PTI Validation",
            "Assign": {
              "Bucket": "{% $states.input.mapS3Bucket %}",
              "ObjectKey": "{% $states.input.mapS3Object %}",
              "SupersededTimetable": "{% $states.input.mapDatasetSupersededTimetable %}",
              "datasetEtlTaskResultId": "{% $states.input.mapDatasetEtlTaskResultId %}",
              "DatasetRevisionId": "{% $states.input.mapDatasetRevisionId %}",
              "FileAttributesEtl": "{% $states.input.mapDatasetFileAttributesEtl %}",
              "DatasetType": "{% $states.input.mapDatasetType %}"
            }
          },
          "PTI Validation": {
            "Type": "Task",
            "Next": "Timetables ETL",
            "Resource": "${PtiValidationLambdaArn}",
            "Arguments": {
              "Bucket": "{% $Bucket %}",
              "ObjectKey": "{% $ObjectKey %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}",
              "TxcFileAttributesId": "{% $FileAttributesEtl %}"
            },
            "Output": {
              "ptiValidation": "{% $states.result %}"
            },
            "Catch": [
              {
                "ErrorEquals": [
                  "States.ALL"
                ],
                "Next": "ETL Exception Handler",
                "Output": {
                  "errorInfo": "{% $states.errorOutput %}",
                  "stepName": "PTI Validation"
                }
              }
            ]
          },
          "Timetables ETL": {
            "Type": "Task",
            "Next": "PTI and ETL Success",
            "Resource": "${EtlProcessLambdaArn}",
            "Arguments": {
              "Bucket": "{% $Bucket %}",
              "ObjectKey": "{% $ObjectKey %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}",
              "TxcFileAttributesId": "{% $FileAttributesEtl %}",
              "SupersededTimetable": "{% $SupersededTimetable %}",
              "DatasetEtlTaskResultId": "{% $datasetEtlTaskResultId %}"
            },
            "Output": {
              "etlProcess": "{% $states.result %}"
            },
            "Catch": [
              {
                "ErrorEquals": [
                  "States.ALL"
                ],
                "Next": "ETL Exception Handler",
                "Output": {
                  "errorInfo": "{% $states.errorOutput %}",
                  "stepName": "Timetables ETL"
                }
              }
            ]
          },
          "PTI and ETL Success": {
            "Type": "Succeed"
          },
          "ETL Exception Handler": {
            "Type": "Task",
            "Next": "PTI and ETL Failed",
            "Resource": "${ExceptionHandlerLambdaArn}",
            "Arguments": {
              "Error": "{% $states.input.errorInfo.Error %}",
              "Cause": "{% $states.input.errorInfo.Cause %}",
              "DatasetEtlTaskResultId": "{% $datasetEtlTaskResultId %}",
              "DatasetRevisionId": "{% $DatasetRevisionId %}",
              "DatasetType": "{% $DatasetType %}",
              "ObjectKey": "{% $ObjectKey %}",
              "StepName": "{% $states.input.stepName %}",
              "FailDatasetRevision": false,
              "FailDatasetETLTaskResult": false
            }
          },
          "PTI and ETL Failed": {
            "Type": "Fail"
          }
        }
      },
      "Output": {
        "etlMapResults": "{% $states.result %}"
      },
      "ResultWriter": {
        "Resource": "arn:aws:states:::s3:putObject",
        "Arguments": {
          "Bucket": "{% $s3Bucket %}",
          "Prefix": "tt-etl-map-results"
        }
      }
    },
    "Generate Output Zip and Update Status": {
      "Type": "Task",
      "Next": "Check Successful File Count",
      "Resource": "${GenerateOutputZipLambdaArn}",
      "Arguments": {
        "MapRunArn": "{% $states.input.etlMapResults.MapRunArn %}",
        "MapRunPrefix": "tt-etl-map-results",
        "DestinationBucket": "{% $s3Bucket %}",
        "OutputPrefix": "{% $ExtractedSubFolder %}",
        "DatasetRevisionId": "{% $datasetRevisionId %}",
        "OriginalObjectKey": "{% $s3Object %}",
        "DatasetEtlTaskResultId": "{% $DatasetEtlTaskResultId %}",
        "PublishDatasetRevision": "{% $publishDatasetRevision %}",
        "OverwriteInputDataset": "{% $overwriteInputDataset %}",
        "DatasetType": "{% $datasetType %}",
        "lockacquiredtime": "{% $lockacquiredtime %}"
      },
      "Assign": {
        "finalResult": "{% $states.result %}"
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "{% $states.errorOutput %}",
            "stepName": "Generate Output Zip and Update Status"
          }
        }
      ]
    },
    "Check Successful File Count": {
      "Type": "Choice",
      "Choices": [
        {
          "Condition": "{% $finalResult.body.successful_files > 0 %}",
          "Next": "Trigger DQS State Machine"
        }
      ],
      "Default": "Release Lock"
    },
    "Trigger DQS State Machine": {
      "Type": "Task",
      "Next": "Release Lock",
      "Resource": "arn:aws:states:::states:startExecution",
      "Arguments": {
        "StateMachineArn": "${DqsStateMachineArn}",
        "Input": {
          "DatasetRevisionId": "{% $datasetRevisionId %}"
        }
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "{% $states.errorOutput %}",
            "stepName": "Trigger DQS State Machine",
            "failDatasetRevision": false,
            "failDatasetETLTaskResult": true
          }
        }
      ]
    },
    "Release Lock": {
      "Type": "Task",
      "Resource": "arn:aws:states:::dynamodb:updateItem",
      "Arguments": {
        "TableName": "${TimetablesSemaphoreDynamoDbTableName}",
        "Key": {
          "LockName": {
            "S": "{% $lock_name %}"
          }
        },
        "ExpressionAttributeNames": {
          "#currentlockcount": "currentlockcount",
          "#lockownerid": "{% $lock_entry %}"
        },
        "ExpressionAttributeValues": {
          ":decrease": {
            "N": "1"
          }
        },
        "UpdateExpression": "SET #currentlockcount = #currentlockcount - :decrease REMOVE #lockownerid",
        "ConditionExpression": "attribute_exists(#lockownerid)",
        "ReturnValues": "UPDATED_NEW"
      },
      "Retry": [
        {
          "ErrorEquals": [
            "DynamoDB.ConditionalCheckFailedException"
          ],
          "MaxAttempts": 0
        },
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "MaxAttempts": 5,
          "BackoffRate": 1.5
        }
      ],
      "Catch": [
        {
          "ErrorEquals": [
            "DynamoDB.ConditionalCheckFailedException"
          ],
          "Next": "Completed"
        },
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Parent Exception Handler",
          "Output": {
            "errorInfo": "$.error",
            "stepName": "Release Lock"
          }
        }
      ],
      "Next": "Completed"
    },
    "Parent Exception Handler": {
      "Type": "Task",
      "Next": "Release Lock Exception Handler",
      "Resource": "${ExceptionHandlerLambdaArn}",
      "Arguments": {
        "Error": "{% $states.input.errorInfo.Error %}",
        "Cause": "{% $states.input.errorInfo.Cause %}",
        "DatasetEtlTaskResultId": "{% $datasetETLTaskResultId %}",
        "DatasetRevisionId": "{% $datasetRevisionId %}",
        "DatasetType": "{% $datasetType %}",
        "StepName": "{% $exists($states.input.stepName) ? $states.input.stepName : 'unknown' %}",
        "ObjectKey": "{% $s3Object %}",
        "Url": "{% $url %}",
        "FailDatasetRevision": "{% $exists($states.input.failDatasetRevision) ? $states.input.failDatasetRevision : true %}",
        "FailDatasetETLTaskResult": "{% $exists($states.input.failDatasetETLTaskResult) ? $states.input.failDatasetRevision : true %}"
      }
    },
    "Release Lock Exception Handler": {
      "Type": "Task",
      "Resource": "arn:aws:states:::dynamodb:updateItem",
      "Arguments": {
        "TableName": "${TimetablesSemaphoreDynamoDbTableName}",
        "Key": {
          "LockName": {
            "S": "{% $lock_name %}"
          }
        },
        "ExpressionAttributeNames": {
          "#currentlockcount": "currentlockcount",
          "#lockownerid": "{% $lock_entry %}"
        },
        "ExpressionAttributeValues": {
          ":decrease": {
            "N": "1"
          }
        },
        "UpdateExpression": "SET #currentlockcount = #currentlockcount - :decrease REMOVE #lockownerid",
        "ConditionExpression": "attribute_exists(#lockownerid)",
        "ReturnValues": "UPDATED_NEW"
      },
      "Retry": [
        {
          "ErrorEquals": [
            "DynamoDB.ConditionalCheckFailedException"
          ],
          "MaxAttempts": 0
        },
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "MaxAttempts": 5,
          "BackoffRate": 1.5
        }
      ],
      "Next": "Overall State Machine Failed",
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Next": "Overall State Machine Failed",
          "Output": "$.releaseError"
        }
      ]
    },
    "Overall State Machine Failed": {
      "Type": "Fail",
      "Comment": "Entire ETL Pipeline Failed"
    },
    "Completed": {
      "Type": "Succeed",
      "Comment": "ETL Process Successully Completed"
    }
  }
}